## AIR Blackbox Gateway â€” Guardrails Configuration
## Copy this file and set GUARDRAILS_CONFIG to enable agent safety detection.
##
## When a guardrail triggers, the gateway returns HTTP 429 with a
## structured error instead of forwarding to the LLM provider.

budgets:
  max_session_tokens: 80000
  max_session_cost_usd: 25

loop_detection:
  similar_prompt_threshold: 0.80
  max_similar_prompts: 5
  window_seconds: 60

tool_protection:
  max_repeat_calls: 3
  repeat_window_seconds: 30

retry_protection:
  max_consecutive_errors: 3

alerts:
  webhook_url: ""  # Slack incoming webhook URL

actions:
  on_trigger:
    - terminate_session
    - block_tool_execution
    - alert_webhook
    - save_replay

## --- Prevention Layer ---
## Runs BEFORE detection. Modifies requests to enforce policies before they
## reach the LLM provider. Prevention returns 403, detection returns 429.
prevention:
  tools:
    enabled: true
    allowlist: []         # empty = allow all (use blocklist instead)
    blocklist:
      - execute_dangerous_command
      - delete_all_data

  pii:
    enabled: true
    block_ssn: true
    block_cc: true
    block_email: false
    block_phone: false
    redact_mode: "redact"  # "block" = reject request, "redact" = replace with [SSN] etc.

  model_limits:
    enabled: false
    cost_per_mtoken:
      "gpt-4o": 0.0025
      "gpt-4o-mini": 0.00015
      "gpt-4": 0.03
      "gpt-3.5-turbo": 0.0005
    cost_threshold_usd: 10.0
    downgrade_map:
      "gpt-4": "gpt-3.5-turbo"
      "gpt-4o": "gpt-4o-mini"

  approval:
    enabled: false
    webhook_url: ""
    timeout_seconds: 30
    rules:
      - token_budget
      - prompt_loop
    fallback_allow: true


## --- Optimization Layer ---
## Aggregates per-model performance metrics, classifies failures, and
## auto-routes requests to better models when one is struggling.
optimization:
  analytics:
    enabled: true          # enable /v1/analytics endpoint + metrics tracking

  router:
    enabled: false          # set true to activate automatic model routing
    rules:
      - from_model: "gpt-4"
        to_model: "gpt-4o"
        condition: "error_rate"
        threshold: 0.20     # route when error rate exceeds 20%
        enabled: true

      - from_model: "gpt-4"
        to_model: "gpt-4o"
        condition: "latency_p95"
        threshold: 10000    # route when p95 latency exceeds 10s
        enabled: true
